{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from dcgan.components.generator import Generator\n",
    "from dcgan.components.discriminator import Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "num_epochs = 150\n",
    "latent_size = 512\n",
    "regWeight = 10\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Fisher(output, gen):\n",
    "    real_label=torch.full((batch_size, ), 1, dtype=torch.float)\n",
    "    l_adv = criterion(output, real_label)\n",
    "    \n",
    "    grad1 = torch.autograd.grad(l_adv, gen, create_graph=True)\n",
    "    fisher = 0\n",
    "    print(len(grad1))\n",
    "    for g in grad1 :\n",
    "        grad2 = torch.autograd.grad(g.sum(), gen, retain_graph=True)\n",
    "        fisher += sum((g2**2).sum() for g2 in grad2)\n",
    "    return fisher / batch_size\n",
    "\n",
    "def loss_adapt(output, gen_param, label):\n",
    "    return nn.BCELoss(output, label) + regWeight * Fisher(output, gen_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adapt_generator = Generator()\n",
    "adapt_discriminator = Discriminator()\n",
    "\n",
    "adapt_generator.load_state_dict(torch.load('models/epoch145_gen.pth'))\n",
    "adapt_discriminator.load_state_dict(torch.load('models/epoch145_dis.pth'))\n",
    "\n",
    "# optimizer_g = optim.Adam(generator.parameters(), lr=0.0006, betas=(0.5, 0.999))\n",
    "# optimizer_d = optim.Adam(discriminator.parameters(), lr=0.0001, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter main.0.weight is initialized with shape torch.Size([2048, 512])\n",
      "Parameter main.3.weight is initialized with shape torch.Size([2048, 1024, 4, 4])\n",
      "Parameter main.4.weight is initialized with shape torch.Size([1024])\n",
      "Parameter main.4.bias is initialized with shape torch.Size([1024])\n",
      "Parameter main.6.weight is initialized with shape torch.Size([1024, 512, 4, 4])\n",
      "Parameter main.7.weight is initialized with shape torch.Size([512])\n",
      "Parameter main.7.bias is initialized with shape torch.Size([512])\n",
      "Parameter main.9.weight is initialized with shape torch.Size([512, 256, 4, 4])\n",
      "Parameter main.10.weight is initialized with shape torch.Size([256])\n",
      "Parameter main.10.bias is initialized with shape torch.Size([256])\n",
      "Parameter main.12.weight is initialized with shape torch.Size([256, 128, 4, 4])\n",
      "Parameter main.13.weight is initialized with shape torch.Size([128])\n",
      "Parameter main.13.bias is initialized with shape torch.Size([128])\n",
      "Parameter main.15.weight is initialized with shape torch.Size([128, 64, 4, 4])\n",
      "Parameter main.16.weight is initialized with shape torch.Size([64])\n",
      "Parameter main.16.bias is initialized with shape torch.Size([64])\n",
      "Parameter main.18.weight is initialized with shape torch.Size([64, 32, 4, 4])\n",
      "Parameter main.19.weight is initialized with shape torch.Size([32])\n",
      "Parameter main.19.bias is initialized with shape torch.Size([32])\n",
      "Parameter main.21.weight is initialized with shape torch.Size([32, 3, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "for name, param in adapt_generator.named_parameters():\n",
    "    if param is None:\n",
    "        print(f\"Parameter {name} is None\")\n",
    "    elif param.nelement() == 0:  # Check if the number of elements in the tensor is zero\n",
    "        print(f\"Parameter {name} is empty (uninitialized)\")\n",
    "    else:\n",
    "        print(f\"Parameter {name} is initialized with shape {param.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\dev\\anaconda\\Lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "grad requires non-empty inputs.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m noise \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(batch_size, latent_size)\n\u001b[1;32m----> 2\u001b[0m loss_adapt(adapt_discriminator(adapt_generator(noise))\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m), adapt_generator\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[1;32mIn[7], line 14\u001b[0m, in \u001b[0;36mloss_adapt\u001b[1;34m(output, gen_param, label)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloss_adapt\u001b[39m(output, gen_param, label):\n\u001b[1;32m---> 14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m nn\u001b[38;5;241m.\u001b[39mBCELoss(output, label) \u001b[38;5;241m+\u001b[39m regWeight \u001b[38;5;241m*\u001b[39m Fisher(output, gen_param)\n",
      "Cell \u001b[1;32mIn[7], line 9\u001b[0m, in \u001b[0;36mFisher\u001b[1;34m(output, gen)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(grad1))\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m g \u001b[38;5;129;01min\u001b[39;00m grad1 :\n\u001b[1;32m----> 9\u001b[0m     grad2 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mgrad(g\u001b[38;5;241m.\u001b[39msum(), gen, retain_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     10\u001b[0m     fisher \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m((g2\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;28;01mfor\u001b[39;00m g2 \u001b[38;5;129;01min\u001b[39;00m grad2)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fisher \u001b[38;5;241m/\u001b[39m batch_size\n",
      "File \u001b[1;32md:\\dev\\anaconda\\Lib\\site-packages\\torch\\autograd\\__init__.py:412\u001b[0m, in \u001b[0;36mgrad\u001b[1;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched, materialize_grads)\u001b[0m\n\u001b[0;32m    408\u001b[0m     result \u001b[38;5;241m=\u001b[39m _vmap_internals\u001b[38;5;241m.\u001b[39m_vmap(vjp, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, allow_none_pass_through\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)(\n\u001b[0;32m    409\u001b[0m         grad_outputs_\n\u001b[0;32m    410\u001b[0m     )\n\u001b[0;32m    411\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 412\u001b[0m     result \u001b[38;5;241m=\u001b[39m _engine_run_backward(\n\u001b[0;32m    413\u001b[0m         t_outputs,\n\u001b[0;32m    414\u001b[0m         grad_outputs_,\n\u001b[0;32m    415\u001b[0m         retain_graph,\n\u001b[0;32m    416\u001b[0m         create_graph,\n\u001b[0;32m    417\u001b[0m         inputs,\n\u001b[0;32m    418\u001b[0m         allow_unused,\n\u001b[0;32m    419\u001b[0m         accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    420\u001b[0m     )\n\u001b[0;32m    421\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m materialize_grads:\n\u001b[0;32m    422\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[0;32m    423\u001b[0m         result[i] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tensor_like(inputs[i])\n\u001b[0;32m    424\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(inputs))\n\u001b[0;32m    425\u001b[0m     ):\n",
      "File \u001b[1;32md:\\dev\\anaconda\\Lib\\site-packages\\torch\\autograd\\graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    745\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    746\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mValueError\u001b[0m: grad requires non-empty inputs."
     ]
    }
   ],
   "source": [
    "noise = torch.randn(batch_size, latent_size)\n",
    "loss_adapt(adapt_discriminator(adapt_generator(noise)).view(-1), adapt_generator.parameters(), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Second derivative for parameter 0:\n",
      "tensor([[ 0.5034, -0.1130, -0.2328]], grad_fn=<TBackward0>)\n",
      "tensor([0.5614], grad_fn=<ViewBackward0>)\n",
      "Second derivative for parameter 1:\n",
      "tensor([[ 1.7936, -0.4027, -0.8294]], grad_fn=<TBackward0>)\n",
      "tensor([2.], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Example model and data\n",
    "model = nn.Linear(3, 1)  # Simple linear model\n",
    "input_data = torch.randn(3)  # Random input\n",
    "target = torch.randn(1)  # Random target\n",
    "\n",
    "# Forward pass\n",
    "output = model(input_data)\n",
    "loss = (output - target).pow(2).mean()  # Mean squared error loss\n",
    "\n",
    "# First derivative (gradient) computation\n",
    "first_grads = torch.autograd.grad(loss, model.parameters(), create_graph=True)\n",
    "\n",
    "# Compute second derivatives (Hessian diagonal) for each parameter\n",
    "second_grads = []\n",
    "for grad in first_grads:\n",
    "    second_grad = torch.autograd.grad(grad.sum(), model.parameters(), create_graph=True)\n",
    "    second_grads.append(second_grad)\n",
    "\n",
    "# Printing second derivatives\n",
    "for i, param in enumerate(model.parameters()):\n",
    "    print(f\"Second derivative for parameter {i}:\")\n",
    "    for grad in second_grads[i]:\n",
    "        print(grad)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
